{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import ndjson\n",
    "import json\n",
    "import time\n",
    "import pandas_gbq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create fake dataset\n",
    "\n",
    "\"\"\"\n",
    "The purpose in this section is to create a fake data set where we can simulate supply chain trailer data.\n",
    "To get the data into into a workable form, we will need to create bins and specific labels for each column.\n",
    "\n",
    "Features we will create:\n",
    "    Sku\n",
    "    inventory\n",
    "    lead time\n",
    "    forecast 3 months\n",
    "    forecase 6 months\n",
    "    sales 1 month\n",
    "    sale 3 months\n",
    "    sale 6 months\n",
    "    potential issue - categorical\n",
    "    pieces past due\n",
    "    min_rec_stock\n",
    "    backorder - output - is the item out of stock or no?\n",
    "    \n",
    "We will create an imbalance in our data by labeling only 5% of items out of stock\n",
    "\"\"\"\n",
    "\n",
    "X,y = make_classification(n_samples=1500000,\n",
    "                          n_features=10,\n",
    "                          n_informative=10,\n",
    "                          n_redundant=0,\n",
    "                          n_repeated=0,\n",
    "                          n_classes=2, weights=[0.95,0.05],flip_y=0, random_state=32)\n",
    "\n",
    "X = pd.DataFrame(X, columns=['inventory', \n",
    "                             'lead_time', \n",
    "                             'forecast_3_mon', \n",
    "                             'forecast_6_mon',\n",
    "                             'sales_1_mon', \n",
    "                             'sales_3_mon', \n",
    "                             'sales_6_mon',\n",
    "                             'potential_issue',\n",
    "                             'pieces_past_due',\n",
    "                             'min_rec_stock'\n",
    "                            ])\n",
    "\n",
    "#Relabel inventory - create 121 bins, label each, and confirm int type\n",
    "inven_labels = [i for i in range(0,31)]\n",
    "X['inventory'] = pd.cut(X['inventory'],31, labels=inven_labels)\n",
    "X['inventory'] = X['inventory'].astype(int)\n",
    "\n",
    "#Relabel lead times - create 10 bins, label each, confirm int type\n",
    "lead_labels = [i for i in range(1,21)]\n",
    "X['lead_time'] = pd.cut(X['lead_time'], 20, labels=lead_labels)\n",
    "X['lead_time'] = X['lead_time'].astype(int)\n",
    "\n",
    "#Relabel forecast 3 and 6 months - make distribution positive by adding random nums to the 3 month forecast\n",
    "#Forecast 3 months\n",
    "X['forecast_3_mon'] = [np.round(i+np.random.randint(10,50),0) for i in X['forecast_3_mon']]\n",
    "\n",
    "#Forecast 6 months - multiply 3 month forecast by random num\n",
    "X['forecast_6_mon'] = [i*np.random.randint(1,3) for i in X['forecast_3_mon']]\n",
    "\n",
    "#Relabel previous sales for 1, 3, and 6 months\n",
    "X['sales_1_mon'] = [np.round(i+np.random.randint(10,20),0) for i in X['sales_1_mon']]\n",
    "\n",
    "#Sales 3 months\n",
    "X['sales_3_mon'] = [i*np.random.randint(1,3) for i in X['sales_1_mon']]\n",
    "\n",
    "#Sales 6 months\n",
    "X['sales_6_mon'] = [i*np.random.randint(1,5) for i in X['sales_3_mon']]\n",
    "\n",
    "#Potential issues\n",
    "issues = (X['sales_1_mon'] > X['inventory']) & (X['lead_time'] < 30)\n",
    "issues = issues.astype(str)\n",
    "\n",
    "issue_list = []\n",
    "for issue in issues:\n",
    "    if issue == 'False':\n",
    "        issue_list.append(0)\n",
    "    else:\n",
    "        issue_list.append(1)\n",
    "        \n",
    "X['potential_issue'] = issue_list\n",
    "\n",
    "#Pieces past due\n",
    "X['pieces_past_due'] = np.round([i*-1 if i < 0 else i for i in X['pieces_past_due']],0)\n",
    "\n",
    "#Min rec stock - setting as a postive value based on sales data\n",
    "min_stock=[]\n",
    "for i,j in zip(X['min_rec_stock'], X['sales_1_mon']):\n",
    "        if (i < 0) & (j > 10):\n",
    "            min_stock.append((i*-1)*5)\n",
    "        elif (i < 0) & (j < 10):\n",
    "            min_stock.append((i*-1)+5)\n",
    "        elif (i > 0) & (j > 10):\n",
    "            min_stock.append(i*5)\n",
    "        else:\n",
    "            min_stock.append(i+5)\n",
    "\n",
    "X['min_rec_stock'] = np.round(min_stock,0)\n",
    "\n",
    "#Add in label for backorder\n",
    "X['backorder'] = y\n",
    "\n",
    "#Add sku id\n",
    "X['sku'] = range(1,len(X['backorder']) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inventory json saved\n",
      "Sales json saved\n",
      "Forecast json saved\n",
      "Inventory ordering json saved\n",
      "Backorder json saved\n",
      "Total time was 0.52 minutes\n"
     ]
    }
   ],
   "source": [
    "#Convert to dicts and save as json\n",
    "\n",
    "\"\"\"\n",
    "In this section, 5 tables will be created\n",
    "    1. Inventory - will include sku, inventory, pieces past due, and min rec stock\n",
    "    2. Sales - will include sku, sales 1 mon, sales 3 mon, and sales 6 mon\n",
    "    3. Forecasts - will include sku, forecast 3 month, forecast 6 month\n",
    "    4. Inventory ordering - will include sku, lead time, and potential issue\n",
    "    5. Backorder - will include sku and if the item went on backorder\n",
    "\"\"\"   \n",
    "start = time.time()\n",
    "\n",
    "#Inventory table\n",
    "inventory = np.asanyarray(X[['sku', 'inventory', 'pieces_past_due', 'min_rec_stock']])\n",
    "inventory_list=[]\n",
    "for i in range(0,len(inventory)):\n",
    "    subset = inventory[i]\n",
    "    record = {'sku' : int(subset[0]),\n",
    "             'inventory': int(subset[1]),\n",
    "             'pieces_past_due': int(subset[2]),\n",
    "             'min_rec_stock': int(subset[3])}\n",
    "    inventory_list.append(record)\n",
    "    \n",
    "#Assert values match and length is the same\n",
    "assert X['sku'][0] == inventory_list[0]['sku']\n",
    "assert len(inventory_list) == len(X['sku']) \n",
    "\n",
    "#save as json (new-line delimited)\n",
    "with open('inventory.ndjson', 'w') as f:\n",
    "    ndjson.dump(inventory_list,f)\n",
    "    \n",
    "#Print that everything is saved\n",
    "print('Inventory json saved')\n",
    "    \n",
    "#Sales table\n",
    "sales = np.asanyarray(X[['sku','sales_1_mon', 'sales_3_mon', 'sales_6_mon']])\n",
    "sales_list=[]\n",
    "for i in range(0,len(sales)):\n",
    "    subset = sales[i]\n",
    "    record = {'sku' : int(subset[0]),\n",
    "             'sales_1_mon': int(subset[1]),\n",
    "             'sales_3_mon': int(subset[2]),\n",
    "             'sales_6_mon': int(subset[3])}\n",
    "    sales_list.append(record)\n",
    "    \n",
    "#Assert values match and length is the same\n",
    "assert X['sku'][0] == sales_list[0]['sku']\n",
    "assert len(sales_list) == len(X['sku'])\n",
    "\n",
    "#save as json (new-line delimited)\n",
    "with open('sales.ndjson', 'w') as f:\n",
    "    ndjson.dump(sales_list,f)\n",
    "    \n",
    "#Print that everything is saved\n",
    "print('Sales json saved')\n",
    "\n",
    "#Forescast table\n",
    "forecast = np.asanyarray(X[['sku','forecast_3_mon', 'forecast_6_mon']])\n",
    "forecast_list=[]\n",
    "for i in range(0,len(forecast)):\n",
    "    subset = forecast[i]\n",
    "    record = {'sku' : int(subset[0]),\n",
    "             'forecast_3_mon': int(subset[1]),\n",
    "             'forecast_6_mon': int(subset[2])}\n",
    "    forecast_list.append(record)\n",
    "    \n",
    "#Assert values match and length is the same\n",
    "assert X['sku'][0] == forecast_list[0]['sku']\n",
    "assert len(forecast_list) == len(X['sku'])\n",
    "\n",
    "#save as json (new-line delimited)\n",
    "with open('forecast.ndjson', 'w') as f:\n",
    "    ndjson.dump(forecast_list,f)\n",
    "    \n",
    "#Print that everything is saved\n",
    "print('Forecast json saved')\n",
    "\n",
    "#Inventory ordering\n",
    "inventory_ordering = np.asanyarray(X[['sku','lead_time', 'potential_issue']])\n",
    "inventory_ordering_list=[]   \n",
    "for i in range(0,len(inventory_ordering)):\n",
    "    subset = inventory_ordering[i]\n",
    "    record = {'sku' : int(subset[0]),\n",
    "             'lead_time': int(subset[1]),\n",
    "             'potential_issue': int(subset[2])}\n",
    "    inventory_ordering_list.append(record)\n",
    "    \n",
    "#Assert values match and length is the same\n",
    "assert X['sku'][0] == inventory_ordering_list[0]['sku']\n",
    "assert len(inventory_ordering_list) == len(X['sku'])\n",
    "\n",
    "#save as json (new-line delimited)\n",
    "with open('inventory_ordering.ndjson', 'w') as f:\n",
    "    ndjson.dump(inventory_ordering_list,f)\n",
    "    \n",
    "#Print that everything is saved\n",
    "print('Inventory ordering json saved')\n",
    "    \n",
    "#Backorder table    \n",
    "backorder = np.asanyarray(X[['sku','backorder']])\n",
    "backorder_list=[]   \n",
    "for i in range(0,len(backorder)):\n",
    "    subset = backorder[i]\n",
    "    record = {'sku' : int(subset[0]),\n",
    "             'backorder': int(subset[1])}\n",
    "    backorder_list.append(record)\n",
    "    \n",
    "#Assert values match and length is the \n",
    "assert X['sku'][0] == backorder_list[0]['sku']\n",
    "assert len(backorder_list) == len(X['sku'])  \n",
    "\n",
    "#save as json (new-line delimited)\n",
    "with open('backorder.ndjson', 'w') as f:\n",
    "    ndjson.dump(backorder_list,f)\n",
    "    \n",
    "#Print that everything is saved\n",
    "print('Backorder json saved')\n",
    "\n",
    "end = time.time()\n",
    "print(\"Total time was \" + str(np.round((end-start)/60,2)) + \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bigquery section\n",
    "\n",
    "\"\"\"\n",
    "1st - Call bigquery and create new dataset then tables\n",
    "2nd - Upload jsons to bigquery\n",
    "3rd - Query the data tables to pull in the necessary information\n",
    "\"\"\"\n",
    "\n",
    "#1 Call bigquery and create new dataset then tables\n",
    "\n",
    "#Call BigQuery\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "#credentials \n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    '****_credentials.json')\n",
    "\n",
    "#Project id name\n",
    "project_id = '****'\n",
    "\n",
    "#create the client\n",
    "client = bigquery.Client(credentials= credentials,project=project_id)\n",
    "\n",
    "#Create new dataset for project\n",
    "DATASET_ID = 'backorder_chain_example'\n",
    "dataset_ref = client.dataset(DATASET_ID)\n",
    "dataset = bigquery.Dataset(dataset_ref)\n",
    "dataset.description = 'my dataset'\n",
    "dataset = client.create_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete stuff from bigquery if needed\n",
    "#client.delete_dataset('steven-data.backorder_chain_example', delete_contents=True)\n",
    "#client.delete_table('steven-data.backorder_chain_example.inventory_ordering')\n",
    "#client.delete_table('steven-data.backorder_chain_example.backorder')\n",
    "#client.delete_table('steven-data.backorder_chain_example.forecast')\n",
    "#client.delete_table('steven-data.backorder_chain_example.sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the tables\n",
    "\n",
    "#Create inventory table\n",
    "dataset_ref = client.dataset('backorder_chain_example')  \n",
    "table_ref = dataset_ref.table('inventory')\n",
    "    \n",
    "SCHEMA = [\n",
    "    bigquery.SchemaField('sku', 'INTEGER', mode='NULLABLE'),\n",
    "    bigquery.SchemaField('inventory', 'INTEGER', mode='NULLABLE'),\n",
    "    bigquery.SchemaField('pieces_past_due', 'INTEGER', mode='NULLABLE'),\n",
    "    bigquery.SchemaField('min_rec_stock', 'INTEGER', mode='NULLABLE'),\n",
    "]\n",
    "table = bigquery.Table(table_ref, schema=SCHEMA)\n",
    "table = client.create_table(table)     \n",
    "\n",
    "assert table.table_id == 'inventory'\n",
    "\n",
    "#Create sales table\n",
    "table_ref = dataset_ref.table('sales')\n",
    "    \n",
    "SCHEMA = [\n",
    "    bigquery.SchemaField('sku', 'INTEGER', mode='NULLABLE'),\n",
    "    bigquery.SchemaField('sales_1_mon', 'INTEGER', mode='NULLABLE'),\n",
    "    bigquery.SchemaField('sales_3_mon', 'INTEGER', mode='NULLABLE'),\n",
    "    bigquery.SchemaField('sales_6_mon', 'INTEGER', mode='NULLABLE'),\n",
    "]\n",
    "table = bigquery.Table(table_ref, schema=SCHEMA)\n",
    "table = client.create_table(table)     \n",
    "\n",
    "assert table.table_id == 'sales'\n",
    "\n",
    "#Create forecast table\n",
    "table_ref = dataset_ref.table('forecast')\n",
    "    \n",
    "SCHEMA = [\n",
    "    bigquery.SchemaField('sku', 'INTEGER', mode='NULLABLE'),\n",
    "    bigquery.SchemaField('forecast_3_mon', 'INTEGER', mode='NULLABLE'),\n",
    "    bigquery.SchemaField('forecast_6_mon', 'INTEGER', mode='NULLABLE'),\n",
    "]\n",
    "table = bigquery.Table(table_ref, schema=SCHEMA)\n",
    "table = client.create_table(table)     \n",
    "\n",
    "assert table.table_id == 'forecast'\n",
    "\n",
    "#Create inventory ordering\n",
    "table_ref = dataset_ref.table('inventory_ordering')\n",
    "    \n",
    "SCHEMA = [\n",
    "    bigquery.SchemaField('sku', 'INTEGER', mode='NULLABLE'),\n",
    "    bigquery.SchemaField('lead_time', 'INTEGER', mode='NULLABLE'),\n",
    "    bigquery.SchemaField('potential_issue', 'INTEGER', mode='NULLABLE'),\n",
    "]\n",
    "table = bigquery.Table(table_ref, schema=SCHEMA)\n",
    "table = client.create_table(table)     \n",
    "\n",
    "assert table.table_id == 'inventory_ordering'\n",
    "\n",
    "#Create backorder table\n",
    "table_ref = dataset_ref.table('backorder')\n",
    "    \n",
    "SCHEMA = [\n",
    "    bigquery.SchemaField('sku', 'INTEGER', mode='NULLABLE'),\n",
    "    bigquery.SchemaField('backorder', 'INTEGER', mode='NULLABLE'),\n",
    "]\n",
    "table = bigquery.Table(table_ref, schema=SCHEMA)\n",
    "table = client.create_table(table)     \n",
    "\n",
    "assert table.table_id == 'backorder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inventory uploaded\n",
      "Sales uploaded\n",
      "Forecast uploaded\n",
      "Inventory ordering uploaded\n",
      "Backorder uploaded\n",
      "Total time was 1.03 minutes\n"
     ]
    }
   ],
   "source": [
    "#Upload jsons to Bigquery\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "#Inventory upload\n",
    "dataset = client.dataset('backorder_chain_example')\n",
    "table = dataset.table('inventory')\n",
    "\n",
    "with open('inventory.ndjson', 'rb') as source_file:\n",
    "    job_config = bigquery.LoadJobConfig()\n",
    "    job_config.source_format = 'NEWLINE_DELIMITED_JSON'\n",
    "    job = client.load_table_from_file(\n",
    "        source_file, table, job_config=job_config)\n",
    "    \n",
    "print('Inventory uploaded')\n",
    "    \n",
    "#Sales upload\n",
    "table = dataset.table('sales')\n",
    "\n",
    "with open('sales.ndjson', 'rb') as source_file:\n",
    "    job_config = bigquery.LoadJobConfig()\n",
    "    job_config.source_format = 'NEWLINE_DELIMITED_JSON'\n",
    "    job = client.load_table_from_file(\n",
    "        source_file, table, job_config=job_config)\n",
    "    \n",
    "print('Sales uploaded')\n",
    "                      \n",
    "#Forecast upload\n",
    "table = dataset.table('forecast')\n",
    "\n",
    "with open('forecast.ndjson', 'rb') as source_file:\n",
    "    job_config = bigquery.LoadJobConfig()\n",
    "    job_config.source_format = 'NEWLINE_DELIMITED_JSON'\n",
    "    job = client.load_table_from_file(\n",
    "        source_file, table, job_config=job_config)\n",
    "\n",
    "print('Forecast uploaded')\n",
    "    \n",
    "#Inventory ordering upload\n",
    "table = dataset.table('inventory_ordering')\n",
    "\n",
    "with open('inventory_ordering.ndjson', 'rb') as source_file:\n",
    "    job_config = bigquery.LoadJobConfig()\n",
    "    job_config.source_format = 'NEWLINE_DELIMITED_JSON'\n",
    "    job = client.load_table_from_file(\n",
    "        source_file, table, job_config=job_config)\n",
    "    \n",
    "print('Inventory ordering uploaded')\n",
    "    \n",
    "#Backorder upload\n",
    "table = dataset.table('backorder')\n",
    "\n",
    "with open('backorder.ndjson', 'rb') as source_file:\n",
    "    job_config = bigquery.LoadJobConfig()\n",
    "    job_config.source_format = 'NEWLINE_DELIMITED_JSON'\n",
    "    job = client.load_table_from_file(\n",
    "        source_file, table, job_config=job_config)\n",
    "\n",
    "print('Backorder uploaded')\n",
    "    \n",
    "end = time.time()\n",
    "print(\"Total time was \" + str(np.round((end-start)/60,2)) + \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas-gbq total time was 2.11 minutes\n",
      "GBQ total time was 2.28 minutes\n"
     ]
    }
   ],
   "source": [
    "#Query Bigquery to join tables and pull in data\n",
    "sql = \"\"\"\n",
    "    SELECT A.sku, A.inventory, A.pieces_past_due, A.min_rec_stock,\n",
    "      B.sales_1_mon, B.sales_3_mon, B.sales_6_mon,\n",
    "      C.forecast_3_mon, C.forecast_6_mon,\n",
    "      D.lead_time, D.potential_issue,\n",
    "      E.backorder\n",
    "FROM `backorder_chain_example.inventory` as A\n",
    "INNER JOIN  `backorder_chain_example.sales`  as B\n",
    "ON A.sku = B.sku\n",
    "INNER JOIN `backorder_chain_example.forecast` as C\n",
    "ON A.sku = C.sku\n",
    "INNER JOIN `backorder_chain_example.inventory_ordering` as D\n",
    "ON A.sku = D.sku\n",
    "INNER JOIN `backorder_chain_example.backorder` as E\n",
    "ON A.sku = E.sku\n",
    "  \"\"\"\n",
    "#results = client.query(sql)\n",
    "start = time.time()\n",
    "\n",
    "df1 = pd.read_gbq(sql, dialect='standard', project_id=project_id)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Query time was \" + str(np.round((end-start)/60,2)) + \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Over sample data using smote\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
